package n.io.prediction.controller

import n.io.prediction.core.BaseEvaluator

import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.rdd.RDD

import scala.reflect._
import scala.reflect.runtime.universe._

/** Base class of evaluator.
  *
  * Evaluator compare predicted result with actual known values and produce numerical
  * comparisons.
  *
  * @tparam EI Evaluation Info class.
  * @tparam Q Input query class.
  * @tparam P Output prediction class.
  * @tparam A Actual value class.
  * @tparam EU Evaluation unit class.
  * @tparam ES Evaluation set class.
  * @tparam ER Evaluation result class.
  * @group Evaluator
  */
abstract class Evaluator[EI, Q, P, A, EU: ClassTag, ES, ER <: AnyRef : ClassTag]
  extends BaseEvaluator[EI, Q, P, A, ER] {
  type EX = Int

  def evaluateBase(sc: SparkContext, evalDataSet: Seq[(EI, RDD[(Q, P, A)])])
  : ER = {
    val evalSetResult: Seq[RDD[(EX, EI, ES)]] = evalDataSet
    .zipWithIndex  // Need to inject an index to keep the order stable.
    .map { case (ed, ex) => {
      val (ei, qpaRDD) = ed

      val euRDD: RDD[EU] = qpaRDD.map { case(q, p, a) => evaluateUnit(q, p, a) }
      val esRDD: RDD[(EX, EI, ES)] = euRDD
        .coalesce(numPartitions = 1, shuffle = true)
        .glom()
        .map { eus => (ex, ei, evaluateSet(ei, eus)) }
      assert (esRDD.partitions.size == 1)
      esRDD
    }}

    val evalSets: RDD[(EX, EI, ES)] = sc.union(evalSetResult)
    val erRDD: RDD[ER] = evalSets
      .coalesce(numPartitions = 1, shuffle = true)
      .glom()
      .map { a => {
        val sorted: Seq[(EI, ES)] = a.sortBy(_._1).map(e => (e._2, e._3))
        evaluateAll(sorted) 
      }}

    val er = erRDD.collect.head
    er
  }

  /** Implement this method to calculate a unit of evaluation, comparing a pair
    * of predicted and actual values.
    *
    * @param query Input query that produced the prediction.
    * @param prediction The predicted value.
    * @param actual The actual value.
    */
  def evaluateUnit(query: Q, prediction: P, actual: A): EU

  /** Implement this method to calculate an overall result of an evaluation set.
    *
    * @param evalInfo Evaluation Info that is related to this evaluation.
    * @param evaluationUnits A list of evaluation units from [[evaluateUnit]].
    */
  def evaluateSet(evalInfo: EI, evaluationUnits: Seq[EU]): ES

  /** Implement this method to aggregate all evaluation result set generated by
    * each evaluation's [[evaluateSet]] to produce the final result.
    *
    * @param input A list of data parameters and evaluation set pairs to aggregate.
    */
  def evaluateAll(input: Seq[(EI, ES)]): ER
}


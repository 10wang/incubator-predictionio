---
title: Installing PredictionIO on Linux / Mac OS X
---

## Quick Install

NOTE: <span class="new">**Note:**</span> PredictionIO can now be installed with a single command:<br />
`$ bash -c "$(curl -s https://install.prediction.io/install.sh)"`

The above script will complete the rest of the instructions on this page for you
so you can skip them.

## Manual Install

If you don't want to use the install script above, you can follow the steps
below to setup PredictionIO and its dependencies.

### Download PredictionIO

Simply download PredictionIO's binary distribution and extract it.

```
$ wget http://download.prediction.io/PredictionIO-<%= data.versions.pio %>.tar.gz
$ tar zxvf PredictionIO-<%= data.versions.pio %>.tar.gz
$ cd PredictionIO-<%= data.versions.pio %>
```

### Installing Dependencies



#### Spark Setup

Apache Spark is the default processing engine for PredictionIO. Download [Apache
Spark release 1.2.0 package hadoop2.4](http://spark.apache.org/downloads.html).
Extract the file, and set the `SPARK_HOME` configuration in `conf/pio-env.sh` to
the Spark directory.

```
$ wget http://d3kbcqa49mib13.cloudfront.net/<%= data.versions.spark_download_filename %>.tgz
$ tar zxvf <%= data.versions.spark_download_filename %>.tgz
```

After that, edit `conf/pio-env.sh` in your PredictionIO installation directory.
For example,

```
SPARK_HOME=/home/abc/Downloads/<%= data.versions.spark_download_filename %>
```

#### Elasticsearch Setup

By default, PredictionIO uses Elasticsearch at localhost as the data store to
store its metadata. Simply download and install
[Elasticsearch](http://www.elasticsearch.org/), which looks like this:

```
$ wget https://download.elasticsearch.org/elasticsearch/elasticsearch/<%= data.versions.elasticsearch_download_filename %>.tar.gz
$ tar zxvf <%= data.versions.elasticsearch_download_filename %>.tar.gz
$ cd <%= data.versions.elasticsearch_download_filename %>
```

If you are using a shared network, change the `network.host` line in
`config/elasticsearch.yml` to `network.host: 127.0.0.1` because by default,
Elasticsearch looks for other machines on the network upon setup and you may run
into weird errors if there are other machines that is also running
Elasticsearch.

If you are not using the default setting at localhost. You may change the
following in `conf/pio-env.sh` to fit your setup.

```
PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch
PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost
PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300
```

#### HBase Setup<a class="anchor" name="hbase">&nbsp;</a>

By default, PredictionIO's Data API uses HBase at localhost as the data store
for event data.

```
$ wget http://archive.apache.org/dist/hbase/<%= data.versions.hbase_basename %>/<%= data.versions.hbase_basename %>-<%= data.versions.hbase_variant %>.tar.gz
$ tar zxvf <%= data.versions.hbase_basename %>-<%= data.versions.hbase_variant %>.tar.gz
$ cd <%= data.versions.hbase_basename %>-<%= data.versions.hbase_dir_suffix %>
```

You will need to at least add a minimal configuration to HBase to start it in
standalone mode. Details can be found
[here](http://hbase.apache.org/book/quickstart.html). Here, we are showing a
sample minimal configuration.

INFO: For production deployment, run a fully distributed HBase configuration.

Edit `conf/hbase-site.xml` and put the following in. You may replace `/home/abc`
with your own home directory.

```
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value>file:///home/abc/hbase</value>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/home/abc/zookeeper</value>
  </property>
</configuration>
```

Edit `conf/hbase-env.sh` to set `JAVA_HOME` for the cluster. For Mac users it
would be

```
export JAVA_HOME=`/usr/libexec/java_home -v 1.7`
```

### Start PredictionIO and Dependent Services

WARNING: Due to a bug in 0.9.0, you must replace `HBASE_CONF_DIR` in
`conf/pio-env.sh` with the absolute path of HBase in order to use
`bin/pio-start-all`, e.g. `HBASE_CONF_DIR=/home/abc/hbase-0.98.6-hadoop2` in the
example above.

Simply do `bin/pio-start-all` and you should see something similar to the
following:

```
$ bin/pio-start-all
Starting Elasticsearch...
Starting HBase...
starting master, logging to /home/abc/<%= data.versions.hbase_basename %>-<%= data.versions.hbase_dir_suffix %>/bin/../logs/hbase-abc-master-yourhost.local.out
Waiting 10 seconds for HBase to fully initialize...
Starting PredictionIO Event Server...
$
```

You may use `jps` to verify that you have everything started:

```
$ jps -l
15344 org.apache.hadoop.hbase.master.HMaster
15409 io.prediction.tools.console.Console
15256 org.elasticsearch.bootstrap.Elasticsearch
15469 sun.tools.jps.Jps
$
```

A running setup will have these up and running:

- io.prediction.tools.console.Console
- org.apache.hadoop.hbase.master.HMaster
- org.elasticsearch.bootstrap.Elasticsearch

At any time, you can run `pio status` to check the status of the dependencies.

Now you have installed everything you need!

#### [Next: Recommendation Engine Quick Start](/templates/recommendation/quickstart/)
